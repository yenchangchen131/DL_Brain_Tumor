"""
å‰µå»ºå®Œæ•´çš„è…¦è…«ç˜¤åˆ†å‰² Jupyter Notebook
"""
import json

# å‰µå»º notebook çµæ§‹
notebook = {
    "cells": [],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

def add_markdown(text):
    """æ·»åŠ  Markdown cell"""
    notebook["cells"].append({
        "cell_type": "markdown",
        "metadata": {},
        "source": text.split('\n')
    })

def add_code(code):
    """æ·»åŠ  Code cell"""
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": code.split('\n')
    })

# ============================================================================
# é–‹å§‹æ§‹å»º notebook
# ============================================================================

# æ¨™é¡Œ
add_markdown("""# è…¦è…«ç˜¤å½±åƒåˆ†å‰²å°ˆæ¡ˆ

é€™æ˜¯ä¸€å€‹å®Œæ•´çš„æ·±åº¦å­¸ç¿’å°ˆæ¡ˆï¼Œä½¿ç”¨ U-Net æ¶æ§‹é€²è¡Œè…¦è…«ç˜¤ MRI å½±åƒåˆ†å‰²ã€‚

## å°ˆæ¡ˆç‰¹è‰²

- âœ… å®Œæ•´çš„ U-Net å¯¦ä½œ
- âœ… è³‡æ–™å¢å¼·ï¼ˆAlbumentationsï¼‰
- âœ… çµ„åˆæå¤±å‡½æ•¸ï¼ˆDice + BCEï¼‰
- âœ… å®Œæ•´çš„è¨“ç·´èˆ‡è©•ä¼°æµç¨‹
- âœ… è¦–è¦ºåŒ–åŠŸèƒ½
- âœ… Windows / GTX 960 å„ªåŒ–è¨­å®š

## ç¡¬é«”éœ€æ±‚

- **å»ºè­°**: NVIDIA GPU (CUDA æ”¯æ´)
- **æœ¬å°ˆæ¡ˆå„ªåŒ–**: GTX 960 4GB
- **æœ€ä½**: CPUï¼ˆæœƒå¾ˆæ…¢ï¼‰

---""")

# 1. ç’°å¢ƒè¨­å®š
add_markdown("""## 1. ç’°å¢ƒè¨­å®š & å¥—ä»¶å°å…¥

é¦–å…ˆè¨­å®šç’°å¢ƒè®Šæ•¸è§£æ±º Windows ç³»çµ±çš„ç›¸å®¹æ€§å•é¡Œï¼Œä¸¦å°å…¥æ‰€æœ‰å¿…è¦çš„å¥—ä»¶ã€‚""")

add_code("""# è§£æ±º Windows ä¸Šçš„ OpenMP è¡çªå•é¡Œ
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

# PyTorch ç›¸é—œ
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.optim.lr_scheduler import ReduceLROnPlateau
import torchvision.transforms as transforms
from torchvision.transforms import functional as TF

# è³‡æ–™è™•ç†
import numpy as np
import cv2
from PIL import Image
import json
from pathlib import Path
from collections import defaultdict

# è¦–è¦ºåŒ–
import matplotlib.pyplot as plt
from tqdm import tqdm
import random

# è³‡æ–™å¢å¼·
import albumentations as A
from albumentations.pytorch import ToTensorV2

print("å¥—ä»¶å°å…¥æˆåŠŸï¼")""")

# GPU æª¢æŸ¥
add_markdown("""### GPU æª¢æŸ¥

æª¢æŸ¥ CUDA æ˜¯å¦å¯ç”¨ï¼Œä»¥åŠ GPU è³‡è¨Šã€‚""")

add_code("""# æª¢æŸ¥ GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è£ç½®: {device}")

if torch.cuda.is_available():
    print(f"GPU åç¨±: {torch.cuda.get_device_name(0)}")
    print(f"GPU æ•¸é‡: {torch.cuda.device_count()}")
    print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
    print(f"é¡¯å­˜ç¸½é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
else:
    print("âš ï¸ CUDA ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨ CPUï¼ˆè¨“ç·´æœƒå¾ˆæ…¢ï¼‰")""")

# 2. è³‡æ–™å¢å¼·
add_markdown("""## 2. è³‡æ–™å¢å¼· & é è™•ç†

ä½¿ç”¨ Albumentations åº«é€²è¡Œè³‡æ–™å¢å¼·ã€‚è¨“ç·´é›†ä½¿ç”¨å¤šç¨®å¢å¼·æŠ€è¡“ï¼Œé©—è­‰é›†åªé€²è¡ŒåŸºæœ¬çš„èª¿æ•´å¤§å°å’Œæ­£è¦åŒ–ã€‚""")

add_code("""class TrainTransform:
    \"\"\"è¨“ç·´é›†çš„è³‡æ–™å¢å¼·\"\"\"
    def __init__(self, image_size=640):
        self.transform = A.Compose([
            A.Resize(image_size, image_size),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.Rotate(limit=15, p=0.5),
            A.RandomBrightnessContrast(p=0.3),
            A.GaussianBlur(p=0.2),
            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),
            A.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            ),
            ToTensorV2()
        ], is_check_shapes=False)
    
    def __call__(self, image, mask):
        transformed = self.transform(image=image, mask=mask)
        return transformed['image'], transformed['mask']


class ValidTransform:
    \"\"\"é©—è­‰é›†/æ¸¬è©¦é›†çš„è³‡æ–™è½‰æ›ï¼ˆä¸å¢å¼·ï¼‰\"\"\"
    def __init__(self, image_size=640):
        self.transform = A.Compose([
            A.Resize(image_size, image_size),
            A.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            ),
            ToTensorV2()
        ], is_check_shapes=False)
    
    def __call__(self, image, mask):
        transformed = self.transform(image=image, mask=mask)
        return transformed['image'], transformed['mask']

print("è³‡æ–™å¢å¼·é¡åˆ¥å®šç¾©å®Œæˆï¼")""")

# 3. Dataset
add_markdown("""## 3. Dataset & DataLoader

è‡ªè¨‚ Dataset é¡åˆ¥ï¼Œå¾ COCO æ ¼å¼çš„æ¨™è¨»æª”æ¡ˆè¼‰å…¥å½±åƒå’Œé®ç½©ã€‚""")

add_code("""class BrainTumorDataset(Dataset):
    \"\"\"è…¦è…«ç˜¤å½±åƒåˆ†å‰²è³‡æ–™é›†\"\"\"
    
    def __init__(self, image_dir, annotation_file, transform=None):
        \"\"\"
        Args:
            image_dir: å½±åƒè³‡æ–™å¤¾è·¯å¾‘
            annotation_file: COCOæ ¼å¼çš„annotation JSONæª”æ¡ˆ
            transform: è³‡æ–™å¢å¼·/è½‰æ›å‡½æ•¸
        \"\"\"
        self.image_dir = Path(image_dir)
        self.transform = transform
        
        # è¼‰å…¥COCO annotations
        with open(annotation_file, 'r', encoding='utf-8') as f:
            self.coco_data = json.load(f)
        
        # å»ºç«‹image idåˆ°æª”åçš„æ˜ å°„
        self.images = {img['id']: img for img in self.coco_data['images']}
        
        # å»ºç«‹image idåˆ°annotationsçš„æ˜ å°„
        self.image_to_anns = defaultdict(list)
        for ann in self.coco_data['annotations']:
            self.image_to_anns[ann['image_id']].append(ann)
        
        # å–å¾—æ‰€æœ‰image ids
        self.image_ids = list(self.images.keys())
    
    def __len__(self):
        return len(self.image_ids)
    
    def __getitem__(self, idx):
        # å–å¾—imageè³‡è¨Š
        image_id = self.image_ids[idx]
        image_info = self.images[image_id]
        
        # è¼‰å…¥å½±åƒ
        image_path = self.image_dir / image_info['file_name']
        image = cv2.imread(str(image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # å»ºç«‹mask
        height, width = image_info['height'], image_info['width']
        mask = self._create_mask(image_id, height, width)
        
        # æ‡‰ç”¨è½‰æ›
        if self.transform:
            image, mask = self.transform(image, mask)
        else:
            # å¦‚æœæ²’æœ‰transformï¼Œè‡³å°‘è½‰æˆtensor
            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0
            mask = torch.from_numpy(mask).unsqueeze(0).float()
        
        return image, mask
    
    def _create_mask(self, image_id, height, width):
        \"\"\"å¾COCO segmentationå»ºç«‹binary mask\"\"\"
        mask = np.zeros((height, width), dtype=np.uint8)
        
        # å–å¾—è©²å½±åƒçš„æ‰€æœ‰annotations
        annotations = self.image_to_anns[image_id]
        
        for ann in annotations:
            if 'segmentation' in ann:
                # COCOæ ¼å¼çš„segmentationå¯èƒ½æ˜¯polygonæˆ–RLE
                if isinstance(ann['segmentation'], list):
                    # Polygonæ ¼å¼
                    for seg in ann['segmentation']:
                        poly = np.array(seg).reshape(-1, 2).astype(np.int32)
                        cv2.fillPoly(mask, [poly], 1)
        
        return mask

print("Dataset é¡åˆ¥å®šç¾©å®Œæˆï¼")""")

# DataLoader å‡½æ•¸
add_code("""def create_dataloaders(train_dir, valid_dir, test_dir, 
                       train_ann, valid_ann, test_ann,
                       batch_size=8, num_workers=4):
    \"\"\"å»ºç«‹è¨“ç·´ã€é©—è­‰ã€æ¸¬è©¦çš„DataLoader\"\"\"
    
    # å»ºç«‹datasets
    train_dataset = BrainTumorDataset(
        train_dir, train_ann, 
        transform=TrainTransform()
    )
    
    valid_dataset = BrainTumorDataset(
        valid_dir, valid_ann,
        transform=ValidTransform()
    )
    
    test_dataset = BrainTumorDataset(
        test_dir, test_ann,
        transform=ValidTransform()
    )
    
    # å»ºç«‹dataloaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True
    )
    
    valid_loader = DataLoader(
        valid_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=1,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    return train_loader, valid_loader, test_loader

print("DataLoader å·¥å» å‡½æ•¸å®šç¾©å®Œæˆï¼")""")

# 4. U-Net æ¨¡å‹
add_markdown("""## 4. U-Net æ¨¡å‹æ¶æ§‹

å¯¦ä½œç¶“å…¸çš„ U-Net æ¶æ§‹ç”¨æ–¼å½±åƒåˆ†å‰²ã€‚""")

add_code("""class DoubleConv(nn.Module):
    \"\"\"(Conv2D -> BatchNorm -> ReLU) * 2\"\"\"
    
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        return self.conv(x)


class UNet(nn.Module):
    \"\"\"U-Netæ¶æ§‹ç”¨æ–¼å½±åƒåˆ†å‰²\"\"\"
    
    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):
        super(UNet, self).__init__()
        self.downs = nn.ModuleList()
        self.ups = nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # Encoder (ä¸‹æ¡æ¨£)
        for feature in features:
            self.downs.append(DoubleConv(in_channels, feature))
            in_channels = feature
        
        # Bottleneck
        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)
        
        # Decoder (ä¸Šæ¡æ¨£)
        for feature in reversed(features):
            self.ups.append(
                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)
            )
            self.ups.append(DoubleConv(feature * 2, feature))
        
        # æœ€çµ‚è¼¸å‡ºå±¤
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)
    
    def forward(self, x):
        skip_connections = []
        
        # Encoder
        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)
        
        # Bottleneck
        x = self.bottleneck(x)
        
        # Decoder
        skip_connections = skip_connections[::-1]
        
        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)
            skip_connection = skip_connections[idx // 2]
            
            # è™•ç†å°ºå¯¸ä¸åŒ¹é…çš„æƒ…æ³
            if x.shape != skip_connection.shape:
                x = TF.resize(x, size=skip_connection.shape[2:])
            
            concat_skip = torch.cat((skip_connection, x), dim=1)
            x = self.ups[idx + 1](concat_skip)
        
        return self.final_conv(x)

print("U-Net æ¨¡å‹å®šç¾©å®Œæˆï¼")""")

# æ¸¬è©¦æ¨¡å‹
add_markdown("""### æ¸¬è©¦æ¨¡å‹å‰µå»º""")
add_code("""# å‰µå»ºæ¨¡å‹ä¸¦æ¸¬è©¦
model = UNet(in_channels=3, out_channels=1)
model = model.to(device)

# è¨ˆç®—åƒæ•¸é‡
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"ç¸½åƒæ•¸é‡: {total_params:,}")
print(f"å¯è¨“ç·´åƒæ•¸é‡: {trainable_params:,}")

# æ¸¬è©¦å‰å‘å‚³æ’­
test_input = torch.randn(1, 3, 640, 640).to(device)
with torch.no_grad():
    output = model(test_input)
print(f"\\næ¸¬è©¦è¼¸å…¥å½¢ç‹€: {test_input.shape}")
print(f"æ¸¬è©¦è¼¸å‡ºå½¢ç‹€: {output.shape}")
print("âœ“ æ¨¡å‹æ¸¬è©¦æˆåŠŸï¼")""")

# 5. æå¤±å‡½æ•¸
add_markdown("""## 5. æå¤±å‡½æ•¸

ä½¿ç”¨çµ„åˆæå¤±å‡½æ•¸ï¼šDice Loss + Binary Cross Entropy""")

add_code("""class DiceLoss(nn.Module):
    \"\"\"Dice Loss for segmentation\"\"\"
    
    def __init__(self, smooth=1.0):
        super(DiceLoss, self).__init__()
        self.smooth = smooth
    
    def forward(self, pred, target):
        # ç¢ºä¿å½¢ç‹€åŒ¹é…
        if pred.dim() == 4 and target.dim() == 3:
            target = target.unsqueeze(1)
        
        # ç¢ºä¿é¡å‹æ­£ç¢º
        target = target.float()
        
        pred = torch.sigmoid(pred)
        
        # Flatten
        pred = pred.view(-1)
        target = target.view(-1)
        
        intersection = (pred * target).sum()
        dice = (2. * intersection + self.smooth) / (
            pred.sum() + target.sum() + self.smooth
        )
        
        return 1 - dice


class CombinedLoss(nn.Module):
    \"\"\"çµ„åˆæå¤±: Dice Loss + Binary Cross Entropy\"\"\"
    
    def __init__(self, dice_weight=0.5, bce_weight=0.5):
        super(CombinedLoss, self).__init__()
        self.dice_loss = DiceLoss()
        self.bce_loss = nn.BCEWithLogitsLoss()
        self.dice_weight = dice_weight
        self.bce_weight = bce_weight
    
    def forward(self, pred, target):
        # ç¢ºä¿ target å’Œ pred çš„å½¢ç‹€åŒ¹é…
        # pred: [B, 1, H, W], targetå¯èƒ½æ˜¯ [B, H, W] æˆ– [B, 1, H, W]
        if pred.dim() == 4 and target.dim() == 3:
            target = target.unsqueeze(1)  # [B, H, W] -> [B, 1, H, W]
        
        # ç¢ºä¿ target æ˜¯ float é¡å‹
        target = target.float()
        
        dice = self.dice_loss(pred, target)
        bce = self.bce_loss(pred, target)
        return self.dice_weight * dice + self.bce_weight * bce

print("æå¤±å‡½æ•¸å®šç¾©å®Œæˆï¼")""")

# 6. è©•ä¼°æŒ‡æ¨™
add_markdown("""## 6. è©•ä¼°æŒ‡æ¨™

å®šç¾© Dice ä¿‚æ•¸ã€IoUã€Precisionã€Recallã€F1 ç­‰è©•ä¼°æŒ‡æ¨™ã€‚""")

add_code("""def dice_coefficient(pred, target, threshold=0.5):
    \"\"\"è¨ˆç®—Diceä¿‚æ•¸\"\"\"
    # ç¢ºä¿å½¢ç‹€åŒ¹é…
    if pred.dim() == 4 and target.dim() == 3:
        target = target.unsqueeze(1)
    
    # ç¢ºä¿é¡å‹æ­£ç¢º
    target = target.float()
    
    pred = (torch.sigmoid(pred) > threshold).float()
    
    intersection = (pred * target).sum()
    dice = (2. * intersection) / (pred.sum() + target.sum() + 1e-8)
    
    return dice.item()


def iou_score(pred, target, threshold=0.5):
    \"\"\"è¨ˆç®—IoU (Intersection over Union)\"\"\"
    # ç¢ºä¿å½¢ç‹€åŒ¹é…
    if pred.dim() == 4 and target.dim() == 3:
        target = target.unsqueeze(1)
    
    # ç¢ºä¿é¡å‹æ­£ç¢º
    target = target.float()
    
    pred = (torch.sigmoid(pred) > threshold).float()
    
    intersection = (pred * target).sum()
    union = pred.sum() + target.sum() - intersection
    iou = intersection / (union + 1e-8)
    
    return iou.item()


def calculate_metrics(pred, target, threshold=0.5):
    \"\"\"è¨ˆç®—æ‰€æœ‰è©•ä¼°æŒ‡æ¨™\"\"\"
    # ç¢ºä¿å½¢ç‹€åŒ¹é…
    if pred.dim() == 4 and target.dim() == 3:
        target = target.unsqueeze(1)
    
    # ç¢ºä¿é¡å‹æ­£ç¢º
    target = target.float()
    
    pred_binary = (torch.sigmoid(pred) > threshold).float()
    
    # True Positives, False Positives, False Negatives
    tp = (pred_binary * target).sum().item()
    fp = (pred_binary * (1 - target)).sum().item()
    fn = ((1 - pred_binary) * target).sum().item()
    
    # Precision, Recall, F1
    precision = tp / (tp + fp + 1e-8)
    recall = tp / (tp + fn + 1e-8)
    f1 = 2 * precision * recall / (precision + recall + 1e-8)
    
    # Dice & IoU
    dice = dice_coefficient(pred, target, threshold)
    iou = iou_score(pred, target, threshold)
    
    return {
        'dice': dice,
        'iou': iou,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

print("è©•ä¼°æŒ‡æ¨™å‡½æ•¸å®šç¾©å®Œæˆï¼")""")

# 7. è¨“ç·´å‡½æ•¸
add_markdown("""## 7. è¨“ç·´ & é©—è­‰å‡½æ•¸

åŒ…å« Early Stoppingã€è¨“ç·´ä¸€å€‹ epochã€é©—è­‰ã€å®Œæ•´è¨“ç·´æµç¨‹ç­‰åŠŸèƒ½ã€‚""")

add_code("""class EarlyStopping:
    \"\"\"Early Stoppingä¾†é˜²æ­¢éæ“¬åˆ\"\"\"
    
    def __init__(self, patience=15, min_delta=0, mode='max'):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        
    def __call__(self, score):
        if self.best_score is None:
            self.best_score = score
        elif self.mode == 'max':
            if score < self.best_score + self.min_delta:
                self.counter += 1
                if self.counter >= self.patience:
                    self.early_stop = True
            else:
                self.best_score = score
                self.counter = 0
        elif self.mode == 'min':
            if score > self.best_score - self.min_delta:
                self.counter += 1
                if self.counter >= self.patience:
                    self.early_stop = True
            else:
                self.best_score = score
                self.counter = 0

print("Early Stopping å®šç¾©å®Œæˆï¼")""")

add_code("""def train_one_epoch(model, loader, criterion, optimizer, device):
    \"\"\"è¨“ç·´ä¸€å€‹epoch\"\"\"
    model.train()
    running_loss = 0.0
    running_dice = 0.0
    
    pbar = tqdm(loader, desc='Training')
    for images, masks in pbar:
        images = images.to(device)
        masks = masks.to(device)
        
        # å‰å‘å‚³æ’­
        outputs = model(images)
        loss = criterion(outputs, masks)
        
        # åå‘å‚³æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # è¨ˆç®—æŒ‡æ¨™
        dice = dice_coefficient(outputs, masks)
        
        running_loss += loss.item()
        running_dice += dice
        
        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'dice': f'{dice:.4f}'
        })
    
    epoch_loss = running_loss / len(loader)
    epoch_dice = running_dice / len(loader)
    
    return epoch_loss, epoch_dice


def validate(model, loader, criterion, device):
    \"\"\"é©—è­‰\"\"\"
    model.eval()
    running_loss = 0.0
    running_dice = 0.0
    
    with torch.no_grad():
        pbar = tqdm(loader, desc='Validation')
        for images, masks in pbar:
            images = images.to(device)
            masks = masks.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, masks)
            dice = dice_coefficient(outputs, masks)
            
            running_loss += loss.item()
            running_dice += dice
            
            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'dice': f'{dice:.4f}'
            })
    
    epoch_loss = running_loss / len(loader)
    epoch_dice = running_dice / len(loader)
    
    return epoch_loss, epoch_dice

print("è¨“ç·´èˆ‡é©—è­‰å‡½æ•¸å®šç¾©å®Œæˆï¼")""")

add_code("""def train_model(model, train_loader, valid_loader, criterion, optimizer, 
                scheduler, device, num_epochs=100, patience=15, 
                save_dir='./models'):
    \"\"\"å®Œæ•´çš„è¨“ç·´æµç¨‹\"\"\"
    
    os.makedirs(save_dir, exist_ok=True)
    best_model_path = os.path.join(save_dir, 'best_model.pth')
    
    early_stopping = EarlyStopping(patience=patience, mode='max')
    
    history = {
        'train_loss': [],
        'train_dice': [],
        'valid_loss': [],
        'valid_dice': [],
        'lr': []
    }
    
    best_dice = 0.0
    
    for epoch in range(num_epochs):
        print(f'\\nEpoch {epoch + 1}/{num_epochs}')
        print('-' * 50)
        
        # è¨“ç·´
        train_loss, train_dice = train_one_epoch(
            model, train_loader, criterion, optimizer, device
        )
        
        # é©—è­‰
        valid_loss, valid_dice = validate(
            model, valid_loader, criterion, device
        )
        
        # å­¸ç¿’ç‡èª¿æ•´
        scheduler.step(valid_dice)
        current_lr = optimizer.param_groups[0]['lr']
        
        # è¨˜éŒ„
        history['train_loss'].append(train_loss)
        history['train_dice'].append(train_dice)
        history['valid_loss'].append(valid_loss)
        history['valid_dice'].append(valid_dice)
        history['lr'].append(current_lr)
        
        print(f'Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}')
        print(f'Valid Loss: {valid_loss:.4f}, Valid Dice: {valid_dice:.4f}')
        print(f'Learning Rate: {current_lr:.6f}')
        
        # å„²å­˜æœ€ä½³æ¨¡å‹
        if valid_dice > best_dice:
            best_dice = valid_dice
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_dice': best_dice,
            }, best_model_path)
            print(f'âœ“ Saved best model (Dice: {best_dice:.4f})')
        
        # Early Stopping
        early_stopping(valid_dice)
        if early_stopping.early_stop:
            print(f'\\nEarly stopping triggered at epoch {epoch + 1}')
            break
    
    return history, best_dice

print("å®Œæ•´è¨“ç·´æµç¨‹å‡½æ•¸å®šç¾©å®Œæˆï¼")""")

# 8. æ¸¬è©¦èˆ‡è¦–è¦ºåŒ–
add_markdown("""## 8. æ¸¬è©¦ & è¦–è¦ºåŒ–

æ¸¬è©¦æ¨¡å‹ä¸¦è¦–è¦ºåŒ–é æ¸¬çµæœã€‚""")

add_code("""def test_model(model, test_loader, device, save_dir='./results'):
    \"\"\"åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°æ¨¡å‹\"\"\"
    model.eval()
    
    all_metrics = []
    os.makedirs(save_dir, exist_ok=True)
    
    with torch.no_grad():
        for idx, (images, masks) in enumerate(tqdm(test_loader, desc='Testing')):
            images = images.to(device)
            masks = masks.to(device)
            
            outputs = model(images)
            metrics = calculate_metrics(outputs, masks)
            all_metrics.append(metrics)
    
    # è¨ˆç®—å¹³å‡æŒ‡æ¨™
    avg_metrics = {
        key: np.mean([m[key] for m in all_metrics])
        for key in all_metrics[0].keys()
    }
    
    return avg_metrics, all_metrics


def visualize_predictions(model, dataset, device, num_samples=5, save_path=None):
    \"\"\"è¦–è¦ºåŒ–é æ¸¬çµæœ\"\"\"
    model.eval()
    
    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4 * num_samples))
    
    indices = random.sample(range(len(dataset)), num_samples)
    
    with torch.no_grad():
        for i, idx in enumerate(indices):
            image, mask = dataset[idx]
            
            # é æ¸¬
            image_input = image.unsqueeze(0).to(device)
            output = model(image_input)
            pred_mask = torch.sigmoid(output).cpu().squeeze().numpy()
            
            # åæ­£è¦åŒ–å½±åƒä»¥ä¾›é¡¯ç¤º
            image_np = image.cpu().numpy().transpose(1, 2, 0)
            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])
            image_np = np.clip(image_np, 0, 1)
            
            mask_np = mask.cpu().squeeze().numpy()
            
            # ç•«åœ–
            axes[i, 0].imshow(image_np)
            axes[i, 0].set_title('Original Image')
            axes[i, 0].axis('off')
            
            axes[i, 1].imshow(mask_np, cmap='gray')
            axes[i, 1].set_title('Ground Truth')
            axes[i, 1].axis('off')
            
            axes[i, 2].imshow(pred_mask, cmap='gray')
            axes[i, 2].set_title('Prediction')
            axes[i, 2].axis('off')
            
            # Overlay
            axes[i, 3].imshow(image_np)
            axes[i, 3].imshow(pred_mask, cmap='jet', alpha=0.5)
            axes[i, 3].set_title('Overlay')
            axes[i, 3].axis('off')
    
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.show()


def plot_training_history(history, save_path=None):
    \"\"\"ç¹ªè£½è¨“ç·´æ­·å²\"\"\"
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    
    # Loss curve
    axes[0].plot(history['train_loss'], label='Train Loss')
    axes[0].plot(history['valid_loss'], label='Valid Loss')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].set_title('Training and Validation Loss')
    axes[0].legend()
    axes[0].grid(True)
    
    # Dice curve
    axes[1].plot(history['train_dice'], label='Train Dice')
    axes[1].plot(history['valid_dice'], label='Valid Dice')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Dice Score')
    axes[1].set_title('Training and Validation Dice Score')
    axes[1].legend()
    axes[1].grid(True)
    
    # Learning rate
    axes[2].plot(history['lr'])
    axes[2].set_xlabel('Epoch')
    axes[2].set_ylabel('Learning Rate')
    axes[2].set_title('Learning Rate Schedule')
    axes[2].set_yscale('log')
    axes[2].grid(True)
    
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.show()

print("æ¸¬è©¦èˆ‡è¦–è¦ºåŒ–å‡½æ•¸å®šç¾©å®Œæˆï¼")""")

# 9. å®Œæ•´è¨“ç·´ç¯„ä¾‹
add_markdown("""## 9. å®Œæ•´è¨“ç·´ç¯„ä¾‹

âš ï¸ **é‡è¦æé†’**: ä»¥ä¸‹æ˜¯å®Œæ•´çš„è¨“ç·´æµç¨‹ç¯„ä¾‹ã€‚

### GTX 960 / Windows ç³»çµ±å„ªåŒ–è¨­å®š

- `BATCH_SIZE = 1` - æœ€ä¿å®ˆè¨­å®šï¼Œé¿å… CUDA timeout
- `NUM_WORKERS = 0` - Windows ç›¸å®¹æ€§
- å·²è¨­å®š `KMP_DUPLICATE_LIB_OK=TRUE` è§£æ±º OpenMP è¡çª

### è¨“ç·´æ™‚é–“é ä¼°

ä½¿ç”¨ GTX 960 4GB:
- æ¯å€‹ epoch: ç´„ 8-12 å°æ™‚
- é è¨ˆç¸½æ™‚é–“: 5-15 å¤©ï¼ˆè¦– Early Stopping è€Œå®šï¼‰

å»ºè­°: è®“è¨“ç·´åœ¨å¤œé–“é‹è¡Œï¼Œå®šæœŸæª¢æŸ¥é€²åº¦ã€‚""")

add_code("""# =============================================================================
# è¨­å®šåƒæ•¸
# =============================================================================

# è³‡æ–™è·¯å¾‘
BASE_DIR = Path('.')
TRAIN_DIR = BASE_DIR / 'train'
VALID_DIR = BASE_DIR / 'valid'
TEST_DIR = BASE_DIR / 'test'

TRAIN_ANN = TRAIN_DIR / '_annotations.coco.json'
VALID_ANN = VALID_DIR / '_annotations.coco.json'
TEST_ANN = TEST_DIR / '_annotations.coco.json'

# è¨“ç·´åƒæ•¸ï¼ˆGTX 960 å„ªåŒ–è¨­å®šï¼‰
BATCH_SIZE = 1       # æœ€ä¿å®ˆè¨­å®šï¼Œç¢ºä¿ç©©å®šè¨“ç·´
NUM_EPOCHS = 100     # æœ€å¤šè¨“ç·´ 100 è¼ª
LEARNING_RATE = 1e-4 # æ¨™æº–å­¸ç¿’ç‡
PATIENCE = 15        # Early Stopping è€å¿ƒå€¼
NUM_WORKERS = 0      # Windows ç³»çµ±å»ºè­°è¨­ç‚º 0

print("åƒæ•¸è¨­å®šå®Œæˆï¼")
print(f"Batch Size: {BATCH_SIZE}")
print(f"Num Workers: {NUM_WORKERS}")
print(f"Device: {device}")""")

add_code("""# =============================================================================
# è¼‰å…¥è³‡æ–™
# =============================================================================

print('\\n' + '='*50)
print('è¼‰å…¥è³‡æ–™...')
print('='*50)

train_loader, valid_loader, test_loader = create_dataloaders(
    train_dir=TRAIN_DIR,
    valid_dir=VALID_DIR,
    test_dir=TEST_DIR,
    train_ann=TRAIN_ANN,
    valid_ann=VALID_ANN,
    test_ann=TEST_ANN,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS
)

print(f'è¨“ç·´é›†æ¨£æœ¬æ•¸: {len(train_loader.dataset)}')
print(f'é©—è­‰é›†æ¨£æœ¬æ•¸: {len(valid_loader.dataset)}')
print(f'æ¸¬è©¦é›†æ¨£æœ¬æ•¸: {len(test_loader.dataset)}')""")

add_code("""# =============================================================================
# å»ºç«‹æ¨¡å‹ã€æå¤±å‡½æ•¸ã€å„ªåŒ–å™¨
# =============================================================================

print('\\n' + '='*50)
print('å»ºç«‹æ¨¡å‹èˆ‡è¨“ç·´çµ„ä»¶...')
print('='*50)

# æ¨¡å‹
model = UNet(in_channels=3, out_channels=1).to(device)
total_params = sum(p.numel() for p in model.parameters())
print(f'æ¨¡å‹åƒæ•¸é‡: {total_params:,}')

# æå¤±å‡½æ•¸
criterion = CombinedLoss(dice_weight=0.5, bce_weight=0.5)

# å„ªåŒ–å™¨
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)

# å­¸ç¿’ç‡èª¿æ•´å™¨
scheduler = ReduceLROnPlateau(
    optimizer, 
    mode='max',
    patience=5,
    factor=0.5,
    verbose=True
)

print("è¨“ç·´çµ„ä»¶å»ºç«‹å®Œæˆï¼")""")

add_code("""# =============================================================================
# é–‹å§‹è¨“ç·´
# =============================================================================

print('\\n' + '='*50)
print('é–‹å§‹è¨“ç·´...')
print('='*50)
print('âš ï¸ è¨“ç·´æ™‚é–“å¯èƒ½å¾ˆé•·ï¼Œè«‹è€å¿ƒç­‰å¾…ï¼')
print('â±ï¸ é ä¼°æ¯å€‹ epoch éœ€è¦ 8-12 å°æ™‚\\n')

# åŸ·è¡Œè¨“ç·´
history, best_dice = train_model(
    model=model,
    train_loader=train_loader,
    valid_loader=valid_loader,
    criterion=criterion,
    optimizer=optimizer,
    scheduler=scheduler,
    device=device,
    num_epochs=NUM_EPOCHS,
    patience=PATIENCE,
    save_dir='./models'
)

print(f'\\nâœ“ è¨“ç·´å®Œæˆï¼æœ€ä½³é©—è­‰ Dice Score: {best_dice:.4f}')""")

add_code("""# =============================================================================
# ç¹ªè£½è¨“ç·´æ›²ç·š
# =============================================================================

# å„²å­˜è¨“ç·´æ­·å²
with open('results/training_history.json', 'w') as f:
    json.dump(history, f, indent=2)

# ç¹ªè£½è¨“ç·´æ›²ç·š
plot_training_history(history, save_path='results/training_curves.png')""")

add_code("""# =============================================================================
# åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°
# =============================================================================

print('\\n' + '='*50)
print('åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°...')
print('='*50)

# è¼‰å…¥æœ€ä½³æ¨¡å‹
checkpoint = torch.load('models/best_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])

# æ¸¬è©¦
avg_metrics, all_metrics = test_model(model, test_loader, device, save_dir='./results')

print('\\næ¸¬è©¦é›†å¹³å‡æŒ‡æ¨™:')
print('-' * 30)
for key, value in avg_metrics.items():
    print(f'{key.capitalize():12s}: {value:.4f}')

# å„²å­˜æ¸¬è©¦çµæœ
with open('results/test_metrics.json', 'w') as f:
    json.dump({
        'average': avg_metrics,
        'all_samples': all_metrics
    }, f, indent=2)""")

add_code("""# =============================================================================
# è¦–è¦ºåŒ–é æ¸¬çµæœ
# =============================================================================

print('\\n' + '='*50)
print('ç”¢ç”Ÿé æ¸¬è¦–è¦ºåŒ–...')
print('='*50)

test_dataset = BrainTumorDataset(
    TEST_DIR, 
    TEST_ANN,
    transform=ValidTransform()
)

visualize_predictions(
    model, 
    test_dataset, 
    device, 
    num_samples=5,
    save_path='results/predictions.png'
)

print('\\nâœ“ æ‰€æœ‰çµæœå·²å„²å­˜è‡³ results/ ç›®éŒ„')""")

# 10. ç–‘é›£æ’è§£
add_markdown("""## 10. ç–‘é›£æ’è§£ & å¸¸è¦‹å•é¡Œ

### CUDA Timeout éŒ¯èª¤

å¦‚æœé‡åˆ° `CUDA error: the launch timed out and was terminated`:
- é™ä½ `BATCH_SIZE` (ç›®å‰å·²æ˜¯æœ€å°å€¼ 1)
- æ¸›å° `image_size` (åœ¨ Transform ä¸­èª¿æ•´ï¼Œä¾‹å¦‚æ”¹ç‚º 512 æˆ– 448)
- è¨“ç·´æ™‚é—œé–‰å…¶ä»–æ‡‰ç”¨ç¨‹å¼

### DataLoader Worker å´©æ½°

Windows ç³»çµ±å¸¸è¦‹å•é¡Œï¼š
- ç¢ºèª `NUM_WORKERS = 0`ï¼ˆç›®å‰å·²è¨­å®šï¼‰

### OpenMP éŒ¯èª¤

å¦‚æœçœ‹åˆ° `OMP: Error #15`:
- ç¢ºèªå·²åŸ·è¡Œ `os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'`ï¼ˆnotebook é–‹é ­å·²è¨­å®šï¼‰

### è¨˜æ†¶é«”ä¸è¶³

å¦‚æœ GPU é¡¯å­˜ä¸è¶³ï¼š
```python
# é™ä½æ‰¹æ¬¡å¤§å°ï¼ˆå·²ç¶“æ˜¯ 1ï¼Œç„¡æ³•å†é™ä½ï¼‰
# é™ä½å½±åƒè§£æåº¦
TrainTransform(image_size=512)  # æˆ– 448
```

### è¨“ç·´å¤ªæ…¢

ä½¿ç”¨ GTX 960 4GB ç¢ºå¯¦æœƒå¾ˆæ…¢ï¼Œå»ºè­°ï¼š
1. é™ä½å½±åƒè§£æåº¦åˆ° 512 æˆ– 448
2. ä½¿ç”¨é›²ç«¯ GPU (Google Colab, Kaggle)
3. è®“è¨“ç·´åœ¨å¤œé–“é€£çºŒé‹è¡Œ

### æª¢æŸ¥ GPU ä½¿ç”¨

é–‹æ–°çš„çµ‚ç«¯åŸ·è¡Œï¼š
```bash
nvidia-smi -l 1
```

ç¢ºèªï¼š
- GPU ä½¿ç”¨ç‡æ¥è¿‘ 100%
- é¡¯å­˜ä½¿ç”¨ < 4GB
- æº«åº¦åœ¨ 70-85Â°C ç¯„åœ

---

## çµèª

é€™å€‹ notebook åŒ…å«äº†å®Œæ•´çš„è…¦è…«ç˜¤åˆ†å‰²å°ˆæ¡ˆç¨‹å¼ç¢¼ï¼Œæ‰€æœ‰åŠŸèƒ½éƒ½å·²æ•´åˆä¸¦å„ªåŒ–ã€‚

**ä¸»è¦ç‰¹è‰²ï¼š**
- âœ… å®Œæ•´çš„ U-Net å¯¦ä½œ
- âœ… æ‰€æœ‰å•é¡Œä¿®æ­£ï¼ˆå½¢ç‹€ã€é¡å‹ã€Windows ç›¸å®¹æ€§ï¼‰
- âœ… GTX 960 å„ªåŒ–è¨­å®š
- âœ… è±å¯Œçš„è¦–è¦ºåŒ–åŠŸèƒ½
- âœ… è©³ç´°çš„èªªæ˜æ–‡å­—

**ç¥è¨“ç·´é †åˆ©ï¼** ğŸš€""")

# å„²å­˜ notebook
with open('c:/DL/DL_Brain_Tumor/brain_tumor_complete.ipynb', 'w', encoding='utf-8') as f:
    json.dump(notebook, f, indent=2, ensure_ascii=False)

print("[OK] Notebook created successfully!")
print("Location: c:/DL/DL_Brain_Tumor/brain_tumor_complete.ipynb")
